{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import RegularPolygon, Ellipse\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import cm, colorbar\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, BaseCrossValidator, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from minisom import MiniSom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('marketing_campaign.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "num_entries = df.shape[0]\n",
    "print(num_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AcceptedCmp1 - 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n",
    "\n",
    "AcceptedCmp2 - 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n",
    "\n",
    "AcceptedCmp3 - 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n",
    "\n",
    "AcceptedCmp4 - 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n",
    "\n",
    "AcceptedCmp5 - 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n",
    "\n",
    "Response (target) - 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "\n",
    "Complain - 1 if customer complained in the last 2 years\n",
    "\n",
    "DtCustomer - date of customer’s enrolment with the company\n",
    "\n",
    "Education - customer’s level of education\n",
    "\n",
    "Marital - customer’s marital status\n",
    "\n",
    "Kidhome - number of small children in customer’s household\n",
    "\n",
    "Teenhome - number of teenagers in customer’s household\n",
    "\n",
    "Income - customer’s yearly household income\n",
    "\n",
    "MntFishProducts - amount spent on fish products in the last 2 years\n",
    "\n",
    "MntMeatProducts - amount spent on meat products in the last 2 years\n",
    "\n",
    "MntFruits - amount spent on fruits products in the last 2 years\n",
    "\n",
    "MntSweetProducts - amount spent on sweet products in the last 2 years\n",
    "\n",
    "MntWines - amount spent on wine products in the last 2 years\n",
    "\n",
    "MntGoldProds - amount spent on gold products in the last 2 years\n",
    "\n",
    "NumDealsPurchases - number of purchases made with discount\n",
    "\n",
    "NumCatalogPurchases - number of purchases made using catalogue\n",
    "\n",
    "NumStorePurchases - number of purchases made directly in stores\n",
    "\n",
    "NumWebPurchases - number of purchases made through company’s web site\n",
    "\n",
    "NumWebVisitsMonth - number of visits to company’s web site in the last month\n",
    "\n",
    "Recency - number of days since the last purchase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print('Number of entries deleted:')\n",
    "print(num_entries - df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_obj = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in col_obj:\n",
    "    print(f'{col}: {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\n",
    "\n",
    "# Creating new variable 'Customer_Age' based on the date of the last submission \n",
    "reference_date = df['Dt_Customer'].max()\n",
    "df['Customer_Age'] = (reference_date - df['Dt_Customer']).dt.days\n",
    "df.drop(columns=['Dt_Customer'], inplace=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=['object']).columns.tolist():\n",
    "    print(f'{df[col].value_counts()}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Marital_Status'] = df['Marital_Status'].replace('Alone', 'Single')\n",
    "df = df[~df['Marital_Status'].isin(['Absurd', 'YOLO'])]\n",
    "\n",
    "for column in df.select_dtypes(include=['object']).columns.tolist():\n",
    "    #print(f'{df[column].value_counts()}\\n\\n')\n",
    "    plt.figure(figsize=(12, 6))  \n",
    "    sns.countplot(data=df, x=column, hue=column, palette=\"tab10\", legend=False)  # Explicitly set hue=column\n",
    "    plt.title(f\"Distribution of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_plot = df.groupby(['Marital_Status', 'Education']).size().reset_index().pivot(columns='Marital_Status', index='Education', values=0)\n",
    "df_plot.apply(lambda x: x/x.sum(), axis=1).plot(kind='bar', stacked=True,  colormap='Set3')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all binaries into 'Int8' variable\n",
    "binary_cols = [col for col in df.columns if df[col].nunique() == 2]\n",
    "df[binary_cols] = df[binary_cols].astype('Int8')\n",
    "print(binary_cols)\n",
    "\n",
    "def percent_plot(var:str, data:pd.DataFrame, target:str):\n",
    "    \"\"\"\n",
    "    Function to calculate the percentage of response based on a specified variable in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        var (str): The name of the column to analyze in the DataFrame.\n",
    "        data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "\n",
    "    Returns:\n",
    "        float: The percentage of response in the specified column.\n",
    "    \"\"\"\n",
    "    total = data.groupby(var).count()[target]\n",
    "    counts = data[data[target] == 1].groupby(var)[target].count()\n",
    "    percentage = (counts / total) * 100\n",
    "\n",
    "    plt.figure(figsize=(12, 6))  \n",
    "    sns.barplot(data=percentage.reset_index(), x=var, y=target, palette='tab10')\n",
    "\n",
    "    plt.title(f\"{target} percentage per {var}\", fontsize=16)\n",
    "    plt.xlabel(f\"{var}\", fontsize=14)\n",
    "    plt.ylabel(f\"Count of {target}\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # percentage.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    # plt.title(f\"{target} percentage per {var}\", fontsize=16)\n",
    "    # plt.xlabel(f\"{var}\", fontsize=14)\n",
    "    # plt.ylabel(f\"Count of {target}\", fontsize=14)\n",
    "    # plt.xticks(rotation=45, fontsize=12)\n",
    "    # plt.yticks(fontsize=12)\n",
    "    # plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "old_cmp = [col for col in df.columns if 'AcceptedCmp' in col]\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns.tolist():\n",
    "    percent_plot(col, df, 'Response')\n",
    "\n",
    "for col in old_cmp:\n",
    "    percent_plot('Marital_Status', df, col)\n",
    "\n",
    "# for col in old_cmp:\n",
    "#     percent_plot('Education', df, col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cmp.append('Response')\n",
    "total_response = df[old_cmp].sum(axis=1)\n",
    "\n",
    "print(total_response.value_counts())\n",
    "\n",
    "for col in old_cmp:\n",
    "    print(f'\\n{df[col].value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers(df, column, threshold=3):\n",
    "    \"\"\"\n",
    "    Counts the number of outliers in a DataFrame column using the Z-score method.\n",
    "    \n",
    "    :param df: Pandas DataFrame\n",
    "    :param column: Name of the column to analyze\n",
    "    :param threshold: Z-score threshold to consider a value as an outlier (default is 3)\n",
    "    :return: Number of outliers\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the DataFrame.\")\n",
    "    \n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    \n",
    "    if std == 0:\n",
    "        return 0  # If the standard deviation is zero, there are no outliers\n",
    "    \n",
    "    z_scores = (df[column] - mean) / std\n",
    "    outliers = df[np.abs(z_scores) > threshold]\n",
    "    return len(outliers)\n",
    "\n",
    "outlier_counts = {\n",
    "    col: count_outliers(df, col, threshold=3)\n",
    "    for col in df.select_dtypes(include=['float64']).columns\n",
    "}\n",
    "\n",
    "outlier_columns = [col for col, count in outlier_counts.items() if count > 0]\n",
    "print(outlier_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in outlier_columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=df, x=col)\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df[col], bins=50, edgecolor='black', alpha=0.7, density=True)\n",
    "    sns.kdeplot(df[col], color='red', linewidth=2)\n",
    "    plt.title(f'Density Plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = [col for col in df.columns if col not in binary_cols and col not in outlier_columns]\n",
    "\n",
    "print(other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Kidhome', 'Teenhome', 'Recency', 'NumStorePurchases','Customer_Age']:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=df, x=col)\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df[col], bins=50, edgecolor='black', alpha=0.7, density=True)\n",
    "    sns.kdeplot(df[col], color='red', linewidth=2)\n",
    "    plt.title(f'Density Plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns, threshold=3):\n",
    "    \"\"\"\n",
    "    Removes outliers from the specified columns in a DataFrame using the Z-score method.\n",
    "    \n",
    "    :param df: Pandas DataFrame\n",
    "    :param columns: List of column names to analyze\n",
    "    :param threshold: Z-score threshold to consider a value as an outlier (default is 3)\n",
    "    :return: DataFrame with outliers removed\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df_clean.columns:\n",
    "            mean = df_clean[column].mean()\n",
    "            std = df_clean[column].std()\n",
    "            \n",
    "            if std == 0:\n",
    "                continue  # Skip if standard deviation is zero\n",
    "            \n",
    "            z_scores = (df_clean[column] - mean) / std\n",
    "            df_clean = df_clean[np.abs(z_scores) <= threshold]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "df = remove_outliers(df, ['Year_Birth', 'Income'])\n",
    "\n",
    "for col in ['Year_Birth', 'Income']:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    q25, q50, q75 = np.percentile(df[col], [25, 50, 75])\n",
    "\n",
    "    sns.violinplot(x=df[col], inner=\"quartile\", color=\"skyblue\")\n",
    "\n",
    "    plt.axvline(q25, color='red', linestyle='dashed', label=f\"Q1 (25%): {q25:.2f}\")\n",
    "    plt.axvline(q50, color='green', linestyle='dashed', label=f\"Median (50%): {q50:.2f}\")\n",
    "    plt.axvline(q75, color='blue', linestyle='dashed', label=f\"Q3 (75%): {q75:.2f}\")\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel(\"Density\", fontsize=12)\n",
    "    plt.title(f\"Distribution of {col}\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_correlations(df, target_var, top_n=5):\n",
    "    \"\"\"\n",
    "    Affiche les variables les plus corrélées avec une variable cible sous forme de heatmap horizontale.\n",
    "\n",
    "    :param df: DataFrame contenant les données.\n",
    "    :param target_var: La variable cible dont on veut voir les corrélations.\n",
    "    :param top_n: Nombre de variables les plus corrélées à afficher.\n",
    "    \"\"\"\n",
    "    # Calculer la corrélation avec la variable cible et trier par valeur absolue (sans supprimer le signe)\n",
    "    correlations = df.corr()[target_var].drop(target_var).sort_values(key=abs, ascending=False).head(top_n)\n",
    "\n",
    "    # Création de la heatmap\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.heatmap(correlations.to_frame(), annot=True, cmap=\"coolwarm\", linewidths=2, fmt=\".6f\",\n",
    "                cbar=True, ax=ax, xticklabels=False, yticklabels=True, center=0)\n",
    "\n",
    "    ax.set_title(f\"Correlation to {target_var}\", fontsize=14, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.show()\n",
    "\n",
    "# Sélection des variables numériques\n",
    "df_corr = df.select_dtypes(include=['float64', 'int64', 'Int8'])\n",
    "plot_top_correlations(df_corr, 'Response', top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-On va laisser l'année car je n'ai pas trouver d'info précise sur la date du dataset, et nous allons standardizer les données plus tard.\n",
    "\n",
    "-Nous avons gardé les valeurs aberrantes pour les variables de montants dépensés car elles seront utiles pour la segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalisation before customer segmentation and models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pareto_distribution(df, column):\n",
    "    \"\"\"\n",
    "    Effectue un test d'hypothèse pour vérifier si une colonne suit une loi de Pareto.\n",
    "    \n",
    "    :param df: DataFrame pandas\n",
    "    :param column: Nom de la colonne à tester\n",
    "    :return: D-statistique et p-value du test de Kolmogorov-Smirnov\n",
    "    \"\"\"\n",
    "    shape, loc, scale = stats.pareto.fit(df[column])\n",
    "    D, p_value = stats.kstest(df[column], 'pareto', args=(shape, loc, scale))\n",
    "    \n",
    "    return {\"column\": column, \"D-statistic\": D, \"p-value\": p_value, \"is_pareto\": p_value > 0.05}\n",
    "\n",
    "pareto_feature = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases']\n",
    "\n",
    "results = [test_pareto_distribution(df, col) for col in pareto_feature]\n",
    "\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated_features = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases']\n",
    "# from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# # pt = PowerTransformer(method='yeo-johnson')\n",
    "# # df[truncated_features] = pt.fit_transform(df[truncated_features])\n",
    "\n",
    "# #df_pareto_log = np.log1p(df[pareto_feature])\n",
    "\n",
    "# # scaler_standard = StandardScaler()\n",
    "# # df_pareto_standard = scaler_standard.fit_transform(df_pareto_log)\n",
    "\n",
    "# #df[pareto_feature] = truncated_features#df_pareto_standard\n",
    "\n",
    "# for col in pareto_feature:\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.hist(df[col], bins=50, edgecolor='black', alpha=0.7, density=True)  # Ajout de density=True\n",
    "#     # distribution (Kernel Density Estimate)\n",
    "#     #sns.kdeplot(df[col], color='red', linewidth=2)\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel(\"Density\")\n",
    "#     plt.title(f\"Distribution of {col}\")\n",
    "#     plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True, dtype='Int8')\n",
    "df.drop(columns=['Z_CostContact', 'Z_Revenue', 'ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Standardize specified columns in a DataFrame using their mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        columns (list): A list of column names to standardize.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A copy of the DataFrame with the specified columns standardized.\n",
    "        dict: A dictionary containing the mean and standard deviation for each standardized column.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    df_copy = df.copy()\n",
    "    df_copy[columns] = scaler.fit_transform(df[columns])\n",
    "    stats = {\n",
    "        col: {\"mean\": scaler.mean_[i], \"std\": scaler.scale_[i]} \n",
    "        for i, col in enumerate(columns)\n",
    "    }\n",
    "    return df_copy, stats\n",
    "\n",
    "def standardize_test_data(df, columns, stats):\n",
    "    \"\"\"\n",
    "    Standardize specified columns in a test DataFrame using the provided mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The test DataFrame to be standardized.\n",
    "        columns (list): A list of column names to standardize.\n",
    "        stats (dict): A dictionary containing the mean and standard deviation for each column \n",
    "                      (from the training dataset).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A copy of the test DataFrame with the specified columns standardized.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    for col in columns:\n",
    "        if col not in stats:\n",
    "            raise ValueError(f\"Statistics for column '{col}' not found in the provided stats.\")\n",
    "        if col not in df_copy.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in the test DataFrame.\")\n",
    "        \n",
    "        mean = stats[col][\"mean\"]\n",
    "        std = stats[col][\"std\"]\n",
    "        \n",
    "        df_copy[col] = (df_copy[col] - mean) / std\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def numeric_columns(df: pd.DataFrame, dtype: str='Int8') -> list:\n",
    "    \"\"\"\n",
    "    Retourne le nom des colonnes numériques d'un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    df : pd.DataFrame\n",
    "        Le DataFrame dont on souhaite obtenir les colonnes numériques.\n",
    "        \n",
    "    Returns:\n",
    "    list\n",
    "        Liste des noms des colonnes numériques.\n",
    "    \"\"\"\n",
    "    return df.select_dtypes(include=[dtype]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric columns and save means and std in a new df to apply SOM\n",
    "# Warning: Si plus tard on utilise les résultats du SOM, il faudra déjà séparer en test et entrainement.\n",
    "# Ici je le fais seulement pour tester SOM\n",
    "\n",
    "col_names = [col for col in df.columns if col not in numeric_columns(df, dtype='Int8')]\n",
    "df_som, param_stand = standardize_columns(df, col_names)\n",
    "#X_test = standardize_test_data(X_test, col_names, param_stand)\n",
    "stats = pd.DataFrame({\n",
    "    'Mean': df_som.mean(),\n",
    "    'Variance': df_som.var()\n",
    "})\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_som.to_csv('data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation with SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activer R dans le notebook\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Charger les librairies\n",
    "install.packages(\"tidyr\")\n",
    "install.packages(\"dplyr\")\n",
    "install.packages(\"cluster\")\n",
    "install.packages(\"kohonen\")\n",
    "install.packages(\"caret\")\n",
    "install.packages(\"randomForest\")\n",
    "install.packages(\"gbm\")\n",
    "install.packages(\"pROC\")\n",
    "\n",
    "library(tidyr)\n",
    "library(dplyr)\n",
    "library(cluster)\n",
    "library(kohonen)\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(gbm)\n",
    "library(pROC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Charger les données\n",
    "df_som <- read.csv(\"marketing_campaign.csv\", sep=\";\")\n",
    "\n",
    "# Statistiques descriptives\n",
    "summary(df_som)\n",
    "\n",
    "# Sélection des variables pour segmentation\n",
    "features <- c(\"Income\", \"Kidhome\", \"Teenhome\", \"MntWines\", \"MntFruits\",\n",
    "              \"MntMeatProducts\", \"MntFishProducts\", \"NumWebPurchases\",\n",
    "              \"NumCatalogPurchases\", \"NumStorePurchases\", \"NumWebVisitsMonth\")\n",
    "\n",
    "# Normalisation des données\n",
    "df_clean <- df_som %>% select(all_of(features)) %>% na.omit()\n",
    "df_scaled <- as.data.frame(scale(df_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "set.seed(1234)\n",
    "# Création du SOM\n",
    "som_grid <- somgrid(xdim = 12, ydim = 12, topo = \"hexagonal\")\n",
    "som_model <- som(as.matrix(df_scaled), grid = som_grid, rlen = 100)\n",
    "\n",
    "# Affichage des clusters SOM\n",
    "plot(som_model, type=\"mapping\", main=\"Carte SOM avec clusters\")\n",
    "\n",
    "# Affichage du nombre d'observations par cluster\n",
    "plot(som_model, type=\"count\", main=\"Nombre d'observations par cluster\")\n",
    "\n",
    "# Affichage des codes SOM (représentation des attributs dans chaque cluster)\n",
    "plot(som_model, type=\"codes\", main=\"Clusters SOM avec attributs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Boucle pour créer les heatmaps\n",
    "for (var in features) {\n",
    "  plot(som_model, type = \"property\", property = df_scaled[[var]],\n",
    "       main = paste(\"Distribution de\", var))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "set.seed(1234)\n",
    "library(cluster)\n",
    "\n",
    "sil_scores <- numeric(10)\n",
    "for (k in 2:10) {\n",
    "  som_codes <- as.matrix(som_model$codes[[1]])\n",
    "  km <- kmeans(som_codes, centers = k, nstart = 10)\n",
    "  sil <- silhouette(km$cluster, dist(som_codes))\n",
    "  sil_scores[k] <- mean(sil[, 3])\n",
    "}\n",
    "\n",
    "plot(2:10, sil_scores[2:10], type = \"b\", pch = 19, frame = FALSE,\n",
    "     xlab = \"Nombre de clusters K\", ylab = \"Indice de silhouette moyen\",\n",
    "     main = \"Indice de Silhouette pour choisir K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "som_codes <- as.matrix(som_model$codes[[1]])  # Extraire la matrice des poids des neurones\n",
    "som_cluster <- cutree(hclust(dist(som_codes)), k = 4)\n",
    "\n",
    "# Affichage des clusters\n",
    "plot(som_model, type = \"codes\", bgcol = som_cluster, main = \"Clusters SOM\")\n",
    "add.cluster.boundaries(som_model, som_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Définition des couleurs des clusters\n",
    "cluster_colors <- c(\"#77BB66\", \"#F37722\", \"#7799DD\", \"#FF99FF\")\n",
    "\n",
    "# Conversion en facteur pour s'assurer que l'ordre des couleurs est respecté\n",
    "som_cluster <- factor(cutree(hclust(dist(som_codes)), k = 4))\n",
    "\n",
    "# Ajustement des marges pour laisser de la place à la légende\n",
    "par(mar = c(5, 4, 4, 5))  # Augmente la marge droite\n",
    "par(oma = c(0, 0, 0, 6))  # Ajoute un espace externe à droite\n",
    "\n",
    "# Définir une mise en page avec 2 parties (graphique + espace pour la légende)\n",
    "layout(matrix(c(1, 2), ncol = 2), widths = c(3, 1))  # 3 parts pour le graph, 1 part pour la légende\n",
    "\n",
    "# Affichage du SOM avec les couleurs personnalisées\n",
    "plot(som_model, type = \"codes\", bgcol = cluster_colors[som_cluster], main = \"Clusters SOM\")\n",
    "\n",
    "# Ajout des frontières des clusters\n",
    "add.cluster.boundaries(som_model, som_cluster)\n",
    "\n",
    "# Passer à l’espace dédié à la légende\n",
    "par(mar = c(0, 0, 0, 0))  # Supprimer les marges pour bien aligner la légende\n",
    "plot.new()  # Créer un plot vide pour placer la légende\n",
    "\n",
    "# Afficher la légende complètement à droite, sans chevauchement\n",
    "legend(\"center\", legend = paste(\"Cluster\", levels(som_cluster)),\n",
    "       fill = cluster_colors, title = \"Clusters\", border = \"black\", bty = \"n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "df_som_clean <- df_som[complete.cases(df_som[, features]), ]  # Keep only the rows used in SOM\n",
    "\n",
    "# Now we can safely add the cluster assignments\n",
    "df_som_clean$Cluster <- som_cluster[som_model$unit.classif]\n",
    "\n",
    "# Contingency table of clusters vs. subscription\n",
    "table(df_som_clean$Cluster, df_som_clean$Response)\n",
    "\n",
    "# Convert to proportions per cluster\n",
    "prop.table(table(df_som_clean$Cluster, df_som_clean$Response), margin = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Ensure df_som_clean has the correct number of rows\n",
    "df_som_clean <- df_som[complete.cases(df_som[, features]), ]\n",
    "\n",
    "# Assign cluster labels to observations\n",
    "df_som_clean$Cluster <- som_cluster[som_model$unit.classif]\n",
    "\n",
    "# Convert Cluster to factor\n",
    "df_som_clean$Cluster <- as.factor(df_som_clean$Cluster)\n",
    "\n",
    "# Generate dummy variables for Cluster\n",
    "dummies <- model.matrix(~ Cluster - 1, data = df_som_clean)\n",
    "\n",
    "# Convert to dataframe and rename columns\n",
    "dummies_df <- as.data.frame(dummies)\n",
    "colnames(dummies_df) <- paste0(\"Cluster_\", levels(df_som_clean$Cluster))\n",
    "\n",
    "# Create final df with only ID and cluster dummies\n",
    "df_clusters <- cbind(df_som_clean[\"ID\"], dummies_df)\n",
    "\n",
    "# Display first rows\n",
    "head(df_clusters, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# Activate the pandas2ri conversion\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Fetch the R dataframe and convert it to Pandas\n",
    "df_clusters = robjects.r['df_clusters']\n",
    "\n",
    "pandas2ri.deactivate()\n",
    "\n",
    "df_merged = pd.merge(df, df_clusters, on=\"ID\", how=\"inner\")\n",
    "df = df_merged\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def describe_clusters(df):\n",
    "    \"\"\"\n",
    "    Affiche une description statistique des variables pour chaque cluster défini par Cluster_1 à Cluster_4.\n",
    "\n",
    "    :param df: DataFrame contenant les colonnes 'Cluster_1' à 'Cluster_4' et d'autres variables numériques.\n",
    "    \"\"\"\n",
    "    for i in range(1, 5):  # Pour Cluster_1 à Cluster_4\n",
    "        cluster_col = f'Cluster_{i}'\n",
    "        if cluster_col in df.columns:\n",
    "            subset = df[df[cluster_col] == 1]  # Filtrer les lignes où Cluster_i == 1\n",
    "            print(f\"Description des variables pour {cluster_col} == 1:\")\n",
    "            print(subset.describe(), \"\\n\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# df = pd.read_csv(\"votre_fichier.csv\")  # Charger votre dataset\n",
    "describe_clusters(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_density_grid(df, cluster_cols, studied_vars):\n",
    "    \"\"\"\n",
    "    Génère une grille de graphiques de densité :\n",
    "    - Colonnes = Clusters\n",
    "    - Lignes = Variables étudiées\n",
    "\n",
    "    :param df: DataFrame contenant les données.\n",
    "    :param cluster_cols: Liste des colonnes de clusters (ex: ['Cluster_1', 'Cluster_2', 'Cluster_3']).\n",
    "    :param studied_vars: Liste des variables à analyser (ex: ['Income', 'MntMeatProducts']).\n",
    "    \"\"\"\n",
    "    n_rows = len(studied_vars)\n",
    "    n_cols = len(cluster_cols)\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 4), sharex=False, sharey=False)\n",
    "\n",
    "    for i, var in enumerate(studied_vars):\n",
    "        if var in df.columns:\n",
    "            for j, cluster in enumerate(cluster_cols):\n",
    "                if cluster in df.columns:\n",
    "                    ax = axes[i, j] if n_rows > 1 and n_cols > 1 else (axes[i] if n_cols == 1 else axes[j])\n",
    "\n",
    "                    sns.kdeplot(df[df[cluster] == 1][var], label=f'{cluster}', shade=True, ax=ax)\n",
    "                    sns.kdeplot(df[var], label='Overall', shade=True, ax=ax)\n",
    "\n",
    "                    ax.set_xlabel(var)\n",
    "                    ax.set_ylabel('Density')\n",
    "                    ax.set_title(f'{var} - {cluster}')\n",
    "                    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "cluster_columns = ['Cluster_1', 'Cluster_2', 'Cluster_3']\n",
    "studied_variables = ['Income', 'MntMeatProducts', 'MntWines', 'MntFruits', 'MntFishProducts']\n",
    "\n",
    "plot_density_grid(df, cluster_columns, studied_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyModel:\n",
    "    \"\"\"\n",
    "    A class to automate model training, evaluation, and selection.\n",
    "\n",
    "    This class provides utilities for:\n",
    "    - Splitting training and testing data.\n",
    "    - Standardize Training and Testing data by saving it on self.stand_params\n",
    "    - Training and evaluating machine learning models.\n",
    "    - Hyperparameter tuning using GridSearchCV.\n",
    "    - Visualizing performance with ROC curves and confusion matrices.\n",
    "    \n",
    "    :param X_train: Training features\n",
    "    :param y_train: Training labels\n",
    "    :param test_size: Fraction of data used for testing\n",
    "    :param random_state: Random seed for reproducibility\n",
    "\n",
    "    Example usage:\n",
    "    ```python\n",
    "    model_manager = EasyModel(X, y)\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Random Forest\": RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Logistic Regression\": {'C': [0.1, 1, 10]},\n",
    "        \"Random Forest\": {'n_estimators': [10, 50, 100]}\n",
    "    }\n",
    "\n",
    "    results = model_manager.model_selection(models, param_grids)\n",
    "    best_model = results[\"Random Forest\"][\"best_estimator\"]\n",
    "    \n",
    "    model_manager.assess_model(best_model)\n",
    "    model_manager.plot_roc_curves({name: res[\"best_estimator\"] for name, res in results.items()})\n",
    "    model_manager.plot_confusion_matrix(best_model)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, test_size: float = 0.2, random_state: int = 42):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                                                random_state=random_state)\n",
    "        self.stand_params = {}\n",
    "\n",
    "    def assess_model(self, estimator: ClassifierMixin):\n",
    "        \"\"\"\n",
    "        Train, predict, and evaluate a model.\n",
    "        \n",
    "        :param estimator: Model of type ClassifierMixin\n",
    "        \"\"\"\n",
    "        try:\n",
    "            estimator.fit(self.X_train, self.y_train)\n",
    "            y_pred = estimator.predict(self.X_test)\n",
    "            score = accuracy_score(self.y_test, y_pred)\n",
    "\n",
    "            print(f\"Accuracy: {score:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(self.y_test, y_pred))\n",
    "            \n",
    "            return score\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model evaluation: {e}\")\n",
    "            return None\n",
    "\n",
    "    def model_selection(self, models: dict, param_grids: dict, cv: int = 5):\n",
    "        \"\"\"\n",
    "        Perform hyperparameter tuning using GridSearchCV for each model.\n",
    "        \n",
    "        :param models: Dictionary of models with their names as keys\n",
    "        :param param_grids: Dictionary of hyperparameter grids corresponding to each model\n",
    "        :param cv: Number of folds for cross-validation\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "\n",
    "        for model_name, estimator in models.items():\n",
    "            if model_name in param_grids:\n",
    "                param_grid = param_grids[model_name]\n",
    "                try:\n",
    "                    grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, \n",
    "                                               cv=cv, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "                    grid_search.fit(self.X_train, self.y_train)\n",
    "                    \n",
    "                    results[model_name] = {\n",
    "                        \"best_estimator\": grid_search.best_estimator_,\n",
    "                        \"best_params\": grid_search.best_params_,\n",
    "                        \"best_score\": grid_search.best_score_\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during model selection for {model_name}: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_roc_curves(self, models: dict):\n",
    "        \"\"\"\n",
    "        Generate ROC curves for given models.\n",
    "        \n",
    "        :param models: Dictionary of trained models with their names as keys\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        best_models = {model: data['best_estimator'] for model, data in models.items()}\n",
    "        for model_name, model in best_models.items():\n",
    "            try:\n",
    "                y_prob = model.predict_proba(self.X_test)[:, 1]\n",
    "                fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                \n",
    "                plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating ROC curve for {model_name}: {e}\")\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, models: ClassifierMixin):\n",
    "        \"\"\"\n",
    "        Generate and display the confusion matrix for a given model.\n",
    "        \n",
    "        :param model: Trained model of type ClassifierMixin\n",
    "        \"\"\"\n",
    "        best_models = {model: data['best_estimator'] for model, data in models.items()}\n",
    "        for model_name, model in best_models.items():\n",
    "            try:\n",
    "                y_pred = model.predict(self.X_test)\n",
    "                cm = confusion_matrix(self.y_test, y_pred)\n",
    "                \n",
    "                plt.figure(figsize=(6, 5))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "                plt.xlabel('Predicted Label')\n",
    "                plt.ylabel('True Label')\n",
    "                plt.title(f'Confusion Matrix of {model_name}')\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating confusion matrix: {e}\")\n",
    "    \n",
    "    def data_profit_curve(self, models: dict, profit: float, cost: float):\n",
    "        \"\"\"\n",
    "        Generate profit curve data for given models.\n",
    "        \n",
    "        :param models: Dictionary of trained models with their names as keys\n",
    "        :param profit: Profit for a correct positive prediction\n",
    "        :param cost: Cost for a false positive prediction\n",
    "        :return: Dictionary with model names as keys and their respective cumulative profit data as values\n",
    "        \"\"\"\n",
    "        profit_data = {}\n",
    "        best_models = {model: data['best_estimator'] for model, data in models.items()}\n",
    "        \n",
    "        for model_name, model in best_models.items():\n",
    "            try:\n",
    "                y_prob = model.predict_proba(self.X_test)[:, 1]\n",
    "                sorted_indices = np.argsort(y_prob)[::-1]\n",
    "                y_sorted = self.y_test.iloc[sorted_indices]\n",
    "                \n",
    "                profits = np.cumsum(y_sorted * profit - (1 - y_sorted) * cost)\n",
    "                profit_data[model_name] = profits\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating profit data for {model_name}: {e}\")\n",
    "        \n",
    "        return profit_data\n",
    "    \n",
    "    def data_best_profit(self, profit_data):\n",
    "        \"\"\"\n",
    "        Get the maximum profit value for each model.\n",
    "\n",
    "        :param profit_data: Dictionary with model names as keys and their respective cumulative profit data as values\n",
    "        :return: Dictionary with model names as keys and their maximum profit values as values\n",
    "        \"\"\"\n",
    "        self.best_profits = {model_name: (np.max(profits), np.argmax(profits)) for model_name, profits in profit_data.items()}\n",
    "        return self.best_profits\n",
    "\n",
    "    \n",
    "    def plot_profit_curve(self, models: dict, profit: float, cost: float):\n",
    "        \"\"\"\n",
    "        Generate and display the profit curve for given models.\n",
    "        \n",
    "        :param models: Dictionary of trained models with their names as keys\n",
    "        :param profit: Profit for a correct positive prediction\n",
    "        :param cost: Cost for a false positive prediction\n",
    "        \"\"\"\n",
    "        profit_data = self.data_profit_curve(models, profit, cost)\n",
    "        best_profits = self.data_best_profit(profit_data)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        colors = {}\n",
    "        for model_name, profits in profit_data.items():\n",
    "            tot_instances = len(profits)\n",
    "            percent_instances = np.linspace(1 / tot_instances, 1, tot_instances) * 100\n",
    "            line, = plt.plot(percent_instances, profits, lw=2, label=f'{model_name}')\n",
    "            colors[model_name] = line.get_color()\n",
    "        \n",
    "        for model_name, best_profit in best_profits.items():\n",
    "            percent_instance_profit = (best_profit[1] / tot_instances) * 100\n",
    "            plt.axvline(x=percent_instance_profit, color=colors[model_name], linestyle='--', label=f'Optimal Call for {model_name}: {best_profit[0]}')\n",
    "            plt.text(percent_instance_profit, -685,\n",
    "                    f'   {percent_instance_profit:.1f}%   ', color=colors[model_name], fontsize=10, ha='center', fontweight='bold')\n",
    "            \n",
    "        plt.xlabel('Number of Instances')\n",
    "        plt.ylabel('Cumulative Profit')\n",
    "        plt.title('Profit Curve for Multiple Models')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "    def mean_profit_curve(self, models: dict, profit: float, cost: float):\n",
    "        \"\"\"\n",
    "        Generate and display the profit curve for given models.\n",
    "        \n",
    "        :param models: Dictionary of trained models with their names as keys\n",
    "        :param profit: Profit for a correct positive prediction\n",
    "        :param cost: Cost for a false positive prediction\n",
    "        \"\"\"\n",
    "        profit_data = self.data_profit_curve(models, profit, cost)\n",
    "        best_profits = self.data_best_profit(profit_data)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        colors = {}\n",
    "        for model_name, profits in profit_data.items():\n",
    "            tot_instances = len(profits)\n",
    "            max_index = int(0.3 * tot_instances)\n",
    "            percent_instances = np.linspace(1 / tot_instances, 1, tot_instances) * 100\n",
    "            mean_profits = profits / np.arange(1, tot_instances + 1)\n",
    "            line, = plt.plot(percent_instances[:max_index], mean_profits[:max_index], lw=2, label=f'{model_name}')\n",
    "            colors[model_name] = line.get_color()\n",
    "\n",
    "        for model_name, best_profit in best_profits.items():\n",
    "            percent_instance_profit = (best_profit[1] / tot_instances) * 100\n",
    "            plt.axvline(x=percent_instance_profit, color=colors[model_name], linestyle='--')\n",
    "            plt.text(percent_instance_profit, 0,\n",
    "                    f'{percent_instance_profit:.1f}%', color=colors[model_name], fontsize=10, ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.xlabel('Percentage of Instances Processed')\n",
    "        plt.ylabel('Mean Profit per Instance')\n",
    "        plt.title('Mean Profit Curve for Multiple Models')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "\n",
    "    def standardize_train_data(self, columns):\n",
    "        \"\"\"\n",
    "        Standardize specified columns in a DataFrame using their mean and standard deviation.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame containing the data.\n",
    "            columns (list): A list of column names to standardize.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A copy of the DataFrame with the specified columns standardized.\n",
    "            dict: A dictionary containing the mean and standard deviation for each standardized column.\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        self.X_train[columns] = scaler.fit_transform(self.X_train[columns])\n",
    "        self.stand_params = {\n",
    "            col: {\"mean\": scaler.mean_[i], \"std\": scaler.scale_[i]} \n",
    "            for i, col in enumerate(columns)\n",
    "        }\n",
    "\n",
    "    def standardize_test_data(self, columns):\n",
    "        \"\"\"\n",
    "        Standardize specified columns in a test DataFrame using the provided mean and standard deviation.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The test DataFrame to be standardized.\n",
    "            columns (list): A list of column names to standardize.\n",
    "            stats (dict): A dictionary containing the mean and standard deviation for each column \n",
    "                        (from the training dataset).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A copy of the test DataFrame with the specified columns standardized.\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            if col not in self.stand_params:\n",
    "                raise ValueError(f\"Statistics for column '{col}' not found in the provided stats.\")\n",
    "            if col not in self.X_test.columns:\n",
    "                raise ValueError(f\"Column '{col}' not found in the test DataFrame.\")\n",
    "            \n",
    "            mean = self.stand_params[col][\"mean\"]\n",
    "            std = self.stand_params[col][\"std\"]\n",
    "            \n",
    "            self.X_test[col] = (self.X_test[col] - mean) / std\n",
    "\n",
    "    def plot_feature_importance(self, model, top_n=40):\n",
    "        \"\"\"\n",
    "        Plots the feature importance for the given model.\n",
    "\n",
    "        :param model: Trained model (must have feature_importances_ attribute)\n",
    "        :param top_n: Number of top features to display (default=20)\n",
    "        \"\"\"\n",
    "        if not hasattr(model, \"feature_importances_\"):\n",
    "            raise ValueError(\"The provided model does not have feature_importances_ attribute.\")\n",
    "\n",
    "        # Importance des variables\n",
    "        feature_importances = model.feature_importances_\n",
    "\n",
    "        # Vérifier que les noms des colonnes existent dans l'objet\n",
    "        if hasattr(self, \"X_train\"):\n",
    "            feature_names = self.X_train.columns\n",
    "        else:\n",
    "            raise ValueError(\"Feature names could not be determined.\")\n",
    "\n",
    "        # Création du DataFrame trié\n",
    "        important_features = pd.Series(feature_importances, index=feature_names).nlargest(top_n)\n",
    "\n",
    "        # Affichage du graphique\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        important_features.plot(kind='barh', color='royalblue')\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.title(f\"Feature importance - {type(model).__name__}\")\n",
    "        plt.gca().invert_yaxis()  # Inverser l'ordre pour meilleure lisibilité\n",
    "        plt.show()\n",
    "\n",
    "    def plot_decision_tree(self, model, max_depth=None):\n",
    "        \"\"\"\n",
    "        Plots the decision tree structure for a trained DecisionTreeClassifier.\n",
    "\n",
    "        :param model: Trained DecisionTreeClassifier model.\n",
    "        :param max_depth: Maximum depth to display in the tree (default=None, shows full tree).\n",
    "        \"\"\"\n",
    "        if not isinstance(model, DecisionTreeClassifier):\n",
    "            raise ValueError(\"The provided model is not a DecisionTreeClassifier.\")\n",
    "\n",
    "        # Création du graphique\n",
    "        plt.figure(figsize=(41, 12))\n",
    "        plot_tree(model, feature_names=self.X_train.columns, class_names=['Non Réponse', 'Réponse'],\n",
    "                  filled=True, rounded=True, fontsize=8, max_depth=max_depth)\n",
    "        plt.title(f\"Decision Tree - {type(model).__name__}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target variable to numeric\n",
    "y = df['Response']\n",
    "\n",
    "# Drop target column\n",
    "X = df.drop(columns=['Response'])\n",
    "\n",
    "model_manager = EasyModel(X, y)\n",
    "col_names = [col for col in df.columns if col not in numeric_columns(df, dtype='Int8')]\n",
    "model_manager.standardize_train_data(col_names)\n",
    "model_manager.standardize_test_data(col_names)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, verbose=0), #, class_weight='balanced'\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "                            'penalty': ['l2', 'elasticnet', 'none', \"l1\"],\n",
    "                            'C': [0.1, 1, 10, 100],\n",
    "                            'max_iter': [100, 200, 300],\n",
    "                            'l1_ratio': [None, 0.1, 0.5, 0.9],  # ratio for combinaision of l1 and l2 in elasticnet\n",
    "                            },\n",
    "\n",
    "    \"DecisionTree\": {\n",
    "                    'max_depth': [10, 20, 30],\n",
    "                    'min_samples_split': [5, 10],\n",
    "                    'min_samples_leaf': [2, 4],\n",
    "                    'criterion': ['gini', 'entropy'],\n",
    "                    'splitter': ['best']\n",
    "                    },                 \n",
    "\n",
    "    \"Random Forest\": {\n",
    "                     'n_estimators': [50],\n",
    "                     'max_depth': [10, 20, 30],\n",
    "                     'min_samples_split': [5, 10],\n",
    "                     'min_samples_leaf': [2, 4],\n",
    "                     'bootstrap': [True],\n",
    "                     'criterion': ['gini'],\n",
    "                     'max_samples': [None, 0.5, 0.8],\n",
    "                     'oob_score': [True]\n",
    "                     },\n",
    "\n",
    "    \"Gradient boosting\": {\n",
    "                         'n_estimators': [50, 100],\n",
    "                         'learning_rate': [0.05, 0.2],\n",
    "                         'max_depth': [3, 5],\n",
    "                         'subsample': [0.8, 1.0]\n",
    "                         }\n",
    "}\n",
    "\n",
    "results = model_manager.model_selection(models, param_grids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results[\"Random Forest\"][\"best_estimator\"]\n",
    "model_manager.assess_model(best_model)\n",
    "model_manager.plot_roc_curves(results)\n",
    "model_manager.plot_confusion_matrix(results)\n",
    "model_manager.plot_profit_curve(results, 11, 3)\n",
    "model_manager.mean_profit_curve(results, 11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_data = model_manager.data_profit_curve(results, 11, 3)\n",
    "for model, profits in profit_data.items():\n",
    "    print('='*50)\n",
    "    print(f\"Profit analysis for {model}\")\n",
    "    print('='*50)\n",
    "    print(f\"Max profit: {max(profits):.2f}\")\n",
    "    print(f\"Mean of profit: {np.mean(profits):.2f}\")\n",
    "    print(f\"Best percent selection: {(np.argmax(profits)/len(profits))*100:.2f}%\")\n",
    "    print('='*50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Gradient boosting\", \"Logistic Regression\"]\n",
    "mod = {model: results[model] for model in models if model in results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manager.plot_roc_curves(mod)\n",
    "model_manager.plot_confusion_matrix(mod)\n",
    "model_manager.plot_profit_curve(mod, 11, 3)\n",
    "model_manager.mean_profit_curve(mod, 11, 3)\n",
    "\n",
    "# Tree models\n",
    "tree = results[\"Gradient boosting\"] #best_model = results[\"Random Forest\"][\"best_estimator\"]\n",
    "model_manager.plot_feature_importance(tree)\n",
    "# model_manager.plot_decision_tree(best_model, max_depth=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_data = model_manager.data_profit_curve(mod, 11, 3)\n",
    "for model, profits in profit_data.items():\n",
    "    print('='*50)\n",
    "    print(f\"Profit analysis for {model}\")\n",
    "    print('='*50)\n",
    "    print(f\"Max profit: {max(profits):.2f}\")\n",
    "    max_profit = np.argmax(profits)\n",
    "    div = np.arange(1, len(profits)+1)\n",
    "    means = profits / div\n",
    "    optimal_mean = means[max_profit]\n",
    "    print(f\"Optimal mean: {optimal_mean:.2f}\")\n",
    "    print(f\"Mean of profit: {np.mean(profits):.2f}\")\n",
    "    print(f\"Best percent selection: {(np.argmax(profits)/len(profits))*100:.2f}%\")\n",
    "    print('='*50)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = np.arange(1, 88)\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC_model = SVC()\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear'],  # Kernels , 'rbf', 'poly', 'sigmoid'\n",
    "#     'degree': [2],  # for polynomial kernel\n",
    "#     'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "#     'coef0': [0.0, 0.1, 0.5],  # for poly and sigmoid\n",
    "#     'tol': [1e-3, 1e-4],  # tolerance to stop algo\n",
    "# }\n",
    "\n",
    "# grid_SVC = model_selection(SVC_model, param_grid=param_grid)\n",
    "# asses_model(SVC_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model = KNeighborsClassifier()\n",
    "\n",
    "# knn_param_grid = {\n",
    "#     'n_neighbors': [10, 15, 20],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#     'metric': ['euclidean', 'manhattan'],\n",
    "# }\n",
    "\n",
    "# grid_knn = model_selection(knn_model, param_grid=knn_param_grid)\n",
    "# asses_model(knn_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
